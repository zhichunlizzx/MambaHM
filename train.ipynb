{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout):\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
      "/local1/zzx/conda/envs/LongSeq/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES = 0\n",
      "Torch sees 1 GPUs\n",
      "Device 0 name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright 2023 Z Zhang\n",
    "\n",
    "# BioSeq2Seq, Version 1.0;\n",
    "# you may not use this file except in compliance with the License.\n",
    "# Use of this code requires following originality guidelines\n",
    "# and declaring the source of the code.\n",
    "# email:zhichunli@mail.dlut.edu.cn\n",
    "# =========================================================================\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "from re import I\n",
    "import numpy as np\n",
    "from model.model_MambaHM import MambaHM\n",
    "from utils.functions import split_based_num\n",
    "from utils.dataloader import RD_dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from torchmetrics import Metric\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "DEVICE=torch.device(\"cuda:0\")\n",
    "\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(\"Torch sees\", torch.cuda.device_count(), \"GPUs\")\n",
    "print(\"Device 0 name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0  # 前10个epoch不变\n",
    "    elif epoch < 20:\n",
    "        return 0.5 ** (epoch - 10)  # 中期慢慢衰减\n",
    "    else:\n",
    "        return (0.5 ** 10) * (0.3 ** (epoch - 20))  # 后期快速衰减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPearsonCorrCoefPerChannel(Metric):\n",
    "    is_differentiable: Optional[bool] = False\n",
    "    higher_is_better: Optional[bool] = True\n",
    "    def __init__(self, n_channels:int, dist_sync_on_step=False):\n",
    "        \"\"\"Calculates the mean pearson correlation across channels aggregated over regions\"\"\"\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.reduce_dims=(0, 1)\n",
    "        self.add_state(\"product\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\", )\n",
    "        self.add_state(\"true\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\", )\n",
    "        self.add_state(\"true_squared\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\", )\n",
    "        self.add_state(\"pred\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\", )\n",
    "        self.add_state(\"pred_squared\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\", )\n",
    "        self.add_state(\"count\", default=torch.zeros(n_channels, dtype=torch.float32), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        self.product += torch.sum(preds * target, dim=self.reduce_dims)\n",
    "        self.true += torch.sum(target, dim=self.reduce_dims)\n",
    "        self.true_squared += torch.sum(torch.square(target), dim=self.reduce_dims)\n",
    "        self.pred += torch.sum(preds, dim=self.reduce_dims)\n",
    "        self.pred_squared += torch.sum(torch.square(preds), dim=self.reduce_dims)\n",
    "        self.count += torch.sum(torch.ones_like(target), dim=self.reduce_dims)\n",
    "\n",
    "    def compute(self):\n",
    "        true_mean = self.true / self.count\n",
    "        pred_mean = self.pred / self.count\n",
    "\n",
    "        covariance = (self.product\n",
    "                    - true_mean * self.pred\n",
    "                    - pred_mean * self.true\n",
    "                    + self.count * true_mean * pred_mean)\n",
    "\n",
    "        true_var = self.true_squared - self.count * torch.square(true_mean)\n",
    "        pred_var = self.pred_squared - self.count * torch.square(pred_mean)\n",
    "        tp_var = torch.sqrt(true_var) * torch.sqrt(pred_var)\n",
    "        correlation = covariance / tp_var\n",
    "        return correlation\n",
    "    \n",
    "\n",
    "def convert_resolution(target, window_width, aim_resolution):\n",
    "    k = aim_resolution // window_width\n",
    "    target = rearrange(target, 'b (r n) d -> b r n d', n = k)\n",
    "    target = torch.mean(target, dim=2)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_genome_file = 'hg19.fa'\n",
    "\n",
    "sequence_data_file = [\n",
    "                        [\n",
    "                        ['K562_ATAC.bw'],\n",
    "                         ]\n",
    "                        \n",
    "                        ]\n",
    "\n",
    "target_seq_file = [\n",
    "    [   \n",
    "        'H3K122ac.bigWig',\n",
    "        'H3K4me1.bigWig', \n",
    "        'H3K4me2.bigWig', \n",
    "        'H3K4me3.bigWig', \n",
    "        'H3K27ac.bigWig', \n",
    "        'H3K27me3.bigWig', \n",
    "        'H3K36me3.bigWig', \n",
    "        'H3K9ac.bigWig', \n",
    "        'H3K9me3.bigWig', \n",
    "        'H4K20me1.bigWig', \n",
    "    ],\n",
    "    \n",
    "    ]\n",
    "\n",
    "include_chr = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8',\n",
    "              'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17',\n",
    "              'chr18', 'chr19', 'chr20', 'chr21', 'chrX']\n",
    "blacklist_file = 'hg19Blacklist.bed'\n",
    "\n",
    "\n",
    "outdir = 'outdir'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "log_dir = os.path.join(outdir, 'log/')\n",
    "model_save = os.path.join(outdir, 'model.pth')\n",
    "\n",
    "\n",
    "\n",
    "train_samples = np.loadtxt('MambaHM/samples/train.bed', dtype=str, delimiter='\\t')\n",
    "validation_samples = np.loadtxt('MambaHM/samples/valid.bed', dtype=str, delimiter='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "window_width = 16\n",
    "\n",
    "batch_size = 4\n",
    "steps_per_epoch = 20 * batch_size\n",
    "num_epochs = 1\n",
    "max_avg_pearson = 0\n",
    "\n",
    "model = MambaHM(channels=384,\n",
    "            num_heads=8,\n",
    "            num_transformer_layers=3,\n",
    "            pooling_type='max',\n",
    "            output_channels=len(target_seq_file[0]),\n",
    "            target_length=7168,\n",
    "            device=DEVICE\n",
    "            ).to(DEVICE)\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=[0])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "lr:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 20/20 [00:37<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(num_epochs):\n",
    "    print('epoch: ', epoch_i)\n",
    "    samples, _ = split_based_num(train_samples, steps_per_epoch)\n",
    "\n",
    "    train_dataset = RD_dataloader(samples,\n",
    "                                reference_genome_file,\n",
    "                                sequence_data_file,\n",
    "                                target_seq_file,\n",
    "                                window_width=window_width,\n",
    "                                extend=40960,\n",
    "                                nan=0,\n",
    "                                rc=False,\n",
    "                                )\n",
    "    data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    metric_train = MeanPearsonCorrCoefPerChannel(n_channels=10)\n",
    "    loss_train = 0\n",
    "    data_iter = iter(data_loader)\n",
    "    model.train()\n",
    "    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    for i in tqdm(range(steps_per_epoch // batch_size), ascii=True):\n",
    "        optimizer.zero_grad()\n",
    "        data_item = next(data_iter)\n",
    "        dna = data_item[0].to(DEVICE)\n",
    "        seq = data_item[1].to(DEVICE)\n",
    "        target = data_item[2].to(DEVICE)\n",
    "        seq_id = data_item[-1]\n",
    "\n",
    "        outputs = model(dna, seq)\n",
    "        loss = criterion(target, outputs)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.)\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "        target_t = target\n",
    "        predicted_t = outputs\n",
    "        metric_train.update(target_t.detach().cpu(), predicted_t.detach().cpu())\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2655it [09:21,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4676, 0.4001, 0.5013, 0.4449, 0.4394, 0.2909, 0.1341, 0.4185, 0.1705,\n",
      "        0.4461])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eva_data_loader = RD_dataloader(validation_samples,\n",
    "                            reference_genome_file,\n",
    "                            sequence_data_file,\n",
    "                            target_seq_file,\n",
    "                            window_width=window_width,\n",
    "                            extend=40960,  \n",
    "                            nan=0,\n",
    "                            valid=True,\n",
    "                            rc=False,\n",
    "                            )\n",
    "eva_dataset = DataLoader(dataset=eva_data_loader, batch_size=1, shuffle=True)\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "loss_test = 0\n",
    "metric = MeanPearsonCorrCoefPerChannel(n_channels=10)\n",
    "model.eval()\n",
    "# model.set_eval()\n",
    "with torch.no_grad():\n",
    "    for i, eva_data_item in tqdm(enumerate(eva_dataset), ascii=True):\n",
    "        if i > len(validation_samples):\n",
    "            break\n",
    "        dna = eva_data_item[0].to(DEVICE)\n",
    "        seq = eva_data_item[1].to(DEVICE)\n",
    "        target = eva_data_item[2].to(DEVICE)\n",
    "        predicted = model(dna, seq)\n",
    "        target_resolution = convert_resolution(target, window_width, 1024).detach().cpu()\n",
    "        predicted_resolution = convert_resolution(predicted, window_width, 1024).detach().cpu()\n",
    "        loss_eva = criterion(target, predicted).mean()\n",
    "        loss_test += loss_eva.item()\n",
    "        \n",
    "        target_t = target_resolution\n",
    "        predicted_t = predicted_resolution\n",
    "        metric.update(target_t, predicted_t)\n",
    "print(metric.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongSeq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
